<img width="1024" height="1536" alt="124" src="https://github.com/user-attachments/assets/fdc54016-7f86-4aa7-893c-68df0dff7093" />

# Jinx ‚Äî Autonomous Engineering Agent

I‚Äôm Jinx. An autonomous engineering agent built for teams that ship. I convert intent into execution: understand goals, generate code, validate, run in a sandbox, and deliver ‚Äî auditable and reproducible by design.

Enterprise standards. Minimal surface area. Maximum signal. Licensed under MIT.

> Built for engineers. Comfortable in regulated environments. Consistent about reliability.

## üöÄ Features

- **Autonomous loop** with safe, sandboxed code execution
- **Durable memory**: `<evergreen>` facts + compact rolling context
- **Embeddings retrieval** from recent dialogue/sandbox for grounded answers
- **Retry/timeout** wrappers around model calls; structured OpenAI request logging
- **Zero‚Äëfriction setup**: optional dependencies ensured at runtime
- **Extensible prompts** via `jinx/prompts/` and configuration

## üìë Table of Contents

- Features
- Star History
- Environment Setup
- Quick Start
- Usage Notes
- Architecture Overview
- Safety Model
- Runtime Flow
- Development Guide
- License
- Security & Compliance
- Responsible AI
- Support

## ‚≠ê Star History

<p align="center">
  <a href="https://star-history.com/#machinegpt/agent&Date">
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=machinegpt/agent&type=Date&theme=dark" onerror="this.src='https://api.star-history.com/svg?repos=machinegpt/agent&type=Date'" />
  </a>
</p>


## üîß Environment Setup

### Python Virtual Environment
Before setting up the project, it's recommended to create a virtual environment. Follow these steps:

Learn about virtual environments: [Python Packaging Guide](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)

Create and activate a virtual environment:

**Windows:**

```
py -m venv .venv
.venv\Scripts\activate
```

**macOS/Linux:**
```
python3 -m venv .venv
source .venv/bin/activate
```

### Project Setup
- Runtime ensures optional dependencies when needed (e.g., `aiofiles`, `prompt_toolkit`). No `requirements.txt` necessary.
- Provide an OpenAI API key and configuration via `.env` at project root. See `.env.example` for all keys:

Required:
```
OPENAI_API_KEY=
```

Optional (defaults in code / example):
```
PULSE=120           # initial error-tolerance pulse
TIMEOUT=300         # seconds before autonomous thinking
OPENAI_MODEL=gpt-5  # model override; service falls back to gpt-5 if unset
# PROXY=socks5://127.0.0.1:12334
```

Create `.env` from the example:

Windows (PowerShell):
```
Copy-Item .env.example .env
```

macOS/Linux:
```
cp .env.example .env
```

## üß† Quick Start
To start the agent:

From a local clone:
```
python jinx.py
```

Alternatively:
```
python -m jinx
```

## üìö Usage Notes

- Place your OpenAI API key in `.env` or system env before start
- Logs live under `log/` (transcript, sandbox, general, embeddings, OpenAI dumps)
- On errors, the system auto-decays a "pulse" to trigger retries and self-healing

## ‚ú® Contributions

Contributions, suggestions, bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss before sending a PR.

## üíñ This project exists in its current state thanks to all the people who contribute
<a href="https://github.com/machinegpt/agent/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=machinegpt/agent" />
</a>

## Disclaimer
This project uses code generated by an AI assistant named Jinx. While Jinx is designed to produce high-quality Python code, not all generated code is manually reviewed. Use with caution, especially in production environments.

---

## üèóÔ∏è Architecture Overview

The runtime is layered, async-first, and auditable:

- **Entrypoint**: `jinx.py`
- **Conversation Orchestrator**: `jinx/conversation/orchestrator.py`
  - Builds standardized headers via `jinx/conversation/formatting.py`
  - Integrates embeddings context (`jinx/embeddings/retrieval.py`)
  - Injects durable `<evergreen>` facts (`jinx/memory/storage.py` ‚Üí `read_evergreen()`)
  - Invokes the model (`jinx/openai_service.py`) and executes code blocks in sandbox
- **Memory Optimization**: `jinx/memory/optimizer.py`
  - Compacts transcript into `<mem_compact>` and persists `<mem_evergreen>`
  - Writes state via `jinx/memory/storage.py`
- **Embeddings**: `jinx/embeddings/pipeline.py`, `jinx/embeddings/retrieval.py`
- **Sandbox**: `jinx/sandbox/*` (separate process, non-blocking)
- **Logging**: targets defined in `jinx/log_paths.py`; OpenAI request dumps under `log/openai/*`
- **Prompts**: configured via `jinx/config.py`, defined under `jinx/prompts/`

### Safety Model (Heuristic "Seatbelt")

- `jinx/codeexec` enforces prompt/validator constraints before execution.
- On any violation or by design, code runs in the sandbox (`jinx/sandbox_service.py`).
- Modules under `jinx/safety/*` and validators reduce risk of unsafe snippets. This is not a hard security boundary.

### Runtime Flow

1. Input received; embeddings context built for the query.
2. Header assembled: `<embeddings_context>` + `<evergreen>` + `<memory>` + optional `<task>/<error>`.
3. Model called; outputs are parsed for executable blocks.
4. Code runs in sandbox; outputs and tails are surfaced; error pulse decays on failures.

## üõ†Ô∏è Development Guide

- **Python**: 3.11+ recommended.
- **Environment**: Place `OPENAI_API_KEY` in `.env` or your environment; `jinx.bootstrap.load_env()` loads it.
- **Start**: `python jinx.py`
- **Logging** (see `jinx/log_paths.py`):
  - Transcript: `log/ink_smeared_diary.txt`
  - User input & executed code: `log/trigger_echoes.txt`
  - General logs: `log/blue_whispers.txt`
  - Sandbox output summary: `log/clockwork_ghost.txt`
  - Sandbox streaming dir: `log/sandbox/`
- **Configuration**:
  - `.env` keys (see `.env.example`): `OPENAI_API_KEY`, `PULSE`, `TIMEOUT`, `OPENAI_MODEL`, optional `PROXY`.
  - `OPENAI_MODEL` env var overrides the default; if unset, service falls back to `gpt-5`.
  - Optional deps are auto-ensured at runtime (e.g., `aiofiles`, `prompt_toolkit`).
 - **Code Style**: Best-effort normalization via `black`, `autopep8`, `libcst` chained in `jinx/formatters/chain.py`.
- **Extensibility**:
  - Add new services under `jinx/` and keep them dependency-light.
  - Prefer pure functions with explicit inputs/outputs.
  - Use async locks for file I/O where interleaving is a concern.

## üìÑ License

This project is licensed under the **MIT License**. See the [`LICENSE`](LICENSE) file for details.

## üß™ Testing Tips

- Keep services small and injectable. The `jinx/contracts.py` file outlines optional Protocols to guide decoupling.
- For sandboxed execution, assert on log file contents rather than stdout.

## üîê Security & Compliance

- **Secrets**: Provide keys via `.env` or environment variables (see `.env.example`). Keys are not logged.
- **Sandbox boundary**: All code generated by the model executes in an isolated sandbox process. This is a safety layer, not a hard security boundary.
- **Logging scope**: Structured logs live under `log/`. Avoid placing sensitive data in prompts. OpenAI request dumps capture instructions and input payloads for auditability.
- **Data retention**: Evergreen memory stores durable facts you explicitly surface; ephemeral transcript is compacted routinely.
- **Network/Dependencies**: Optional dependencies are ensured at runtime; pin if your environment requires deterministic builds.

## ü§ñ Responsible AI

- Human-in-the-loop recommended for critical paths.
- Deterministic audit trail: inputs, headers, model outputs, and executed code are logged.
- No training occurs on your data within this repository. External model behavior is governed by your chosen provider‚Äôs policies.

## üí¨ Support

- File issues and feature requests in GitHub Issues.
- For questions and design proposals, open a Discussion or start with an Issue to scope the change.
