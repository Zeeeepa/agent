<img width="1024" height="1536" alt="124" src="https://github.com/user-attachments/assets/fdc54016-7f86-4aa7-893c-68df0dff7093" />

# Agent

A high-velocity, self-sufficient Python AI agent framework that leverages the OpenAI Python SDK to interpret natural-language commands, generate and execute code dynamically, and manage its runtime environment with zero friction. It features automated dependency installation, secure environment configuration, structured logging, and a minimalist plugin interface for embedding powerful Python tools‚Äîall under the permissive Apache 2.0 license.

## ‚≠ê Star History

<p align="center">
  <a href="https://star-history.com/#machinegpt/agent&Date">
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=machinegpt/agent&type=Date&theme=dark" onerror="this.src='https://api.star-history.com/svg?repos=machinegpt/agent&type=Date'" />
  </a>
</p>


## üîß Environment Setup

### Python Virtual Environment
Before setting up the project, it's recommended to create a virtual environment. Follow these steps:

Learn about virtual environments: [Python Packaging Guide](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)

Create and activate a virtual environment:

**Windows:**

```
py -m venv .venv
.venv\Scripts\activate
```

**macOS/Linux:**
```
python3 -m venv .venv
source .venv/bin/activate
```

### Project Setup
Dependencies are auto-installed at runtime; no requirements.txt or install.py is needed.
This project requires an OpenAI API key to function. To provide it, create a .env file in the root directory with the following content:
```
OPENAI_API_KEY=
```
Alternatively, you can copy the provided .env.example file and update the key:
```
cp .env.example .env
```

## üß† Start
To start the agent, simply run:
```
git clone https://github.com/machinegpt/agent.git
cd agent

python jinx.py
```

## ‚ú® Contributions

Contributions, suggestions, bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss before sending a PR.

## üíñ This project exists in its current state thanks to all the people who contribute
<a href="https://github.com/machinegpt/agent/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=machinegpt/agent" />
</a>

## Disclaimer
This project uses code generated by an AI assistant named Jinx. While Jinx is designed to produce high-quality Python code, not all generated code is manually reviewed. Use with caution, especially in production environments.

---

## üèóÔ∏è Architecture Overview

The runtime follows a clean layered structure for clarity and testability:

- **Entrypoint**: `jinx.py` invokes `jinx.orchestrator.main()` with a safe exit boundary.
- **Orchestrator**: `jinx/orchestrator.py` bridges sync CLI to the async core.
- **Async Core**: `jinx/runtime_service.py` wires the event loop:
  - Input: `jinx/input_service.py` pushes sanitized user input into a queue.
  - Spinner: `jinx/spinner_service.py` renders a non-blocking indicator.
  - Conversation: `jinx/conversation_service.py` coordinates model, parsing, exec.
- **Services**:
  - OpenAI: `jinx/openai/*` builds instruction headers and calls the SDK.
  - Parsing: `jinx/parser/*` extracts tagged blocks for execution.
  - Execution: `jinx/exec/*` formats, validates, and executes code; falls back to sandbox on taboo.
  - Sandbox: `jinx/sandbox/*` runs snippets in a separate process and funnels output/errors back.
  - Logging: `jinx/logging/*` appends to transcript and logs with an async lock.
  - Bootstrap: `jinx/bootstrap/*` provides opt-in dependency bootstrapping and dotenv loading.
  - Text/FS/Retry/etc.: `jinx/text/*`, `jinx/fs/*`, `jinx/retry/*`.

### Safety Model (Heuristic "Seatbelt")

- Safety micro-modules in `jinx/safety/*` provide taboo substrings and checks:
  - `chaos_taboo` list, `find_violations()`, `is_code_safe()`, `assert_code_safe()`.
- `jinx/exec/*` enforces prompt constraints and uses sandbox execution when taboo substrings are present.
- `jinx/exec_service.py` enforces prompt constraints and uses sandbox execution when taboo substrings are present.
- This is not a security boundary; it reduces risk for accidental unsafe snippets.

### Runtime Flow

1. Banner renders via `jinx/banner_service.py`.
2. `neon_input()` streams user input into an `asyncio.Queue`.
3. For each item, `conversation_service.shatter()` prompts the model and parses output.
4. First executable code block (if found) is executed; output/errors are logged.
5. Pulse is adjusted via `jinx/error_service.py`, driving the spinner and exit behavior.

## üõ†Ô∏è Development Guide

- **Python**: 3.11+ recommended.
- **Environment**: Place `OPENAI_API_KEY` in `.env` or your environment; `jinx.bootstrap.load_env()` loads it.
- **Start**: `python jinx.py`
- **Logging**:
  - Transcript: `log/soul_fragment.txt`
  - User input: `log/detonator.txt`
  - General logs: `log/cortex_wail.txt`
  - Exec output (sandbox/inline): `log/nano_doppelganger.txt`
- **Configuration**:
  - `PULSE`: initial spinner pulse (default 100)
  - `TIMEOUT`: inactivity seconds before `<no_response>` (default 30)
  - `OPENAI_MODEL`: override model id (default `gpt-5`)
  - `PROXY`: optional HTTP(S)/SOCKS proxy URL for the OpenAI client
- **Code Style**: Best-effort normalization via `black`, `autopep8`, `libcst` in `jinx/format_service.py`.
- **Extensibility**:
  - Add new services under `jinx/` and keep them dependency-light.
  - Prefer pure functions with explicit inputs/outputs.
  - Use async locks for file I/O where interleaving is a concern.

## üß™ Testing Tips

- Keep services small and injectable. The `jinx/contracts.py` file outlines optional Protocols to guide decoupling.
- For sandboxed execution, assert on log file contents rather than stdout.
