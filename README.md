<img width="1024" height="1536" alt="124" src="https://github.com/user-attachments/assets/fdc54016-7f86-4aa7-893c-68df0dff7093" />

# Agent

A high-velocity, self-sufficient Python AI agent framework that leverages the OpenAI Python SDK to interpret natural-language commands, generate and execute code dynamically, and manage its runtime environment with zero friction. It features automated dependency installation, secure environment configuration, structured logging, and a minimalist plugin interface for embedding powerful Python tools‚Äîall under the permissive Apache 2.0 license.

## ‚≠ê Star History

<p align="center">
  <a href="https://star-history.com/#machinegpt/agent&Date">
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=machinegpt/agent&type=Date&theme=dark" onerror="this.src='https://api.star-history.com/svg?repos=machinegpt/agent&type=Date'" />
  </a>
</p>


## üîß Environment Setup

### Python Virtual Environment
Before setting up the project, it's recommended to create a virtual environment. Follow these steps:

Learn about virtual environments: [Python Packaging Guide](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)

Create and activate a virtual environment:

**Windows:**

```
py -m venv .venv
.venv\Scripts\activate
```

**macOS/Linux:**
```
python3 -m venv .venv
source .venv/bin/activate
```

### Project Setup
- Runtime ensures optional dependencies when needed (e.g., `aiofiles`, `prompt_toolkit`). No `requirements.txt` necessary.
- Provide an OpenAI API key and configuration via `.env` at project root. See `.env.example` for all keys:

Required:
```
OPENAI_API_KEY=
```

Optional (defaults in code / example):
```
PULSE=120           # initial error-tolerance pulse
TIMEOUT=300         # seconds before autonomous thinking
OPENAI_MODEL=gpt-5  # model override; service falls back to gpt-5 if unset
# PROXY=socks5://127.0.0.1:12334
```

Create `.env` from the example:

Windows (PowerShell):
```
Copy-Item .env.example .env
```

macOS/Linux:
```
cp .env.example .env
```

## üß† Start
To start the agent:

From a local clone:
```
python jinx.py
```

Alternatively:
```
python -m jinx
```

## ‚ú® Contributions

Contributions, suggestions, bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss before sending a PR.

## üíñ This project exists in its current state thanks to all the people who contribute
<a href="https://github.com/machinegpt/agent/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=machinegpt/agent" />
</a>

## Disclaimer
This project uses code generated by an AI assistant named Jinx. While Jinx is designed to produce high-quality Python code, not all generated code is manually reviewed. Use with caution, especially in production environments.

---

## üèóÔ∏è Architecture Overview

The runtime is layered and fully async for clarity and testability:

- **Entrypoint**: `jinx.py` calls `jinx.orchestrator.main()` with a safe exit boundary.
- **Orchestrator**: `jinx/orchestrator.py` loads env via `jinx.bootstrap.load_env()`, ensures optional deps (e.g., `aiofiles`), then runs the async core.
- **Async Core**: `jinx/runtime_service.py` shows the banner, creates a bounded `asyncio.Queue`, and launches:
  - `jinx.runtime.input_task.start_input_task()` ‚Äî streams user input into the queue.
  - `jinx.runtime.frame_shift.frame_shift()` ‚Äî drives conversation and spinner pipeline.
- **Conversation**: `jinx/conversation_service.py` builds prompt chains, invokes the model, renders neatly boxed output, and coordinates execution and error decay.
- **Model I/O**: `jinx/openai_service.py` builds instruction headers via `jinx.openai_mod.*`, calls the OpenAI SDK with retry (`jinx/retry.py`).
- **Parsing/Execution**:
  - Validators: `jinx/codeexec` provides constraint checks (`collect_violations`).
  - Execution: `jinx/exec_service.py` formats code and always executes in sandbox.
  - Sandbox: `jinx/sandbox_service.py` delegates to `jinx.sandbox.async_runner.run_sandbox` (separate process, non-blocking).
- **UI/Spinner**: `jinx/spinner_service.py` renders a non-blocking spinner with phrases from `jinx/spinner/*`.
- **Logging**: `jinx/logging_service.py` with log targets from `jinx/log_paths.py`.
- **Prompts**: active prompt configured via `jinx/config.py` (`PROMPT_NAME`, default "burning_logic"); available under `jinx/prompts/`.

### Safety Model (Heuristic "Seatbelt")

- `jinx/codeexec` enforces prompt/validator constraints before execution.
- On any violation or by design, code runs in the sandbox (`jinx/sandbox_service.py`).
- Modules under `jinx/safety/*` and validators reduce risk of unsafe snippets. This is not a hard security boundary.

### Runtime Flow

1. Banner via `jinx/banner_service.py`.
2. Input task feeds a bounded queue.
3. Conversation step (`shatter`) calls the model, parses executable blocks, and runs them in the sandbox.
4. Output and sandbox tail are surfaced; pulse decays on errors via `jinx/error_service.py`.

## üõ†Ô∏è Development Guide

- **Python**: 3.11+ recommended.
- **Environment**: Place `OPENAI_API_KEY` in `.env` or your environment; `jinx.bootstrap.load_env()` loads it.
- **Start**: `python jinx.py`
- **Logging** (see `jinx/log_paths.py`):
  - Transcript: `log/ink_smeared_diary.txt`
  - User input & executed code: `log/trigger_echoes.txt`
  - General logs: `log/blue_whispers.txt`
  - Sandbox output summary: `log/clockwork_ghost.txt`
  - Sandbox streaming dir: `log/sandbox/`
- **Configuration**:
  - `.env` keys (see `.env.example`): `OPENAI_API_KEY`, `PULSE`, `TIMEOUT`, `OPENAI_MODEL`, optional `PROXY`.
  - `OPENAI_MODEL` env var overrides the default; if unset, service falls back to `gpt-5`.
  - Optional deps are auto-ensured at runtime (e.g., `aiofiles`, `prompt_toolkit`).
- **Code Style**: Best-effort normalization via `black`, `autopep8`, `libcst` in `jinx/format_service.py`.
- **Extensibility**:
  - Add new services under `jinx/` and keep them dependency-light.
  - Prefer pure functions with explicit inputs/outputs.
  - Use async locks for file I/O where interleaving is a concern.

## üß™ Testing Tips

- Keep services small and injectable. The `jinx/contracts.py` file outlines optional Protocols to guide decoupling.
- For sandboxed execution, assert on log file contents rather than stdout.
