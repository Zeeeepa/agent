# Jinx Agent - Complete Codebase Analysis

## Executive Summary

**Jinx** is an autonomous engineering agent designed for production environments. It converts intent into execution through sandboxed code execution, durable memory systems, and embeddings-based retrieval. The agent is enterprise-grade, MIT-licensed, and built with a micro-modular architecture.

---

## ğŸ¯ Core Architecture

### 1. Entry Points

#### **Primary Entry Point: `jinx.py`**
```python
Location: ./jinx.py
Purpose: CLI bootstrap for Jinx agent runtime
Key Function: Delegates to jinx.orchestrator.main()
```

**Responsibilities:**
- Minimal dependency entrypoint
- Exception handling boundary
- Graceful interrupt handling (Ctrl+C â†’ exit code 130)
- Fatal error capture with stderr logging

#### **Secondary Entry Points:**
- `jinx/orchestrator.py` - Main orchestration logic
- `jinx/micro/conversation/orchestrator.py` - Conversation-level orchestration
- `jinx/conversation/orchestrator.py` - Legacy conversation handler

---

## ğŸ“ Directory Structure & Components

### Core Modules

```
jinx/
â”œâ”€â”€ __init__.py                     # Package initialization
â”œâ”€â”€ orchestrator.py                 # Main orchestration engine
â”œâ”€â”€ config.py                       # Configuration management
â”œâ”€â”€ settings.py                     # Settings system
â”œâ”€â”€ utils.py                        # Utility functions
â”œâ”€â”€ retry.py                        # Retry logic with backoff
â”œâ”€â”€ autotune.py                     # Auto-tuning mechanisms
â”œâ”€â”€ supervisor.py                   # Process supervision
â”œâ”€â”€ watchdog.py                     # File watching system
â”‚
â”œâ”€â”€ bootstrap/                      # Bootstrap & dependency management
â”‚   â”œâ”€â”€ env.py                     # Environment setup
â”‚   â”œâ”€â”€ installer.py               # Dependency installer
â”‚   â””â”€â”€ deps.py                    # Dependency definitions
â”‚
â”œâ”€â”€ openai_mod/                     # OpenAI integration
â”‚   â”œâ”€â”€ caller.py                  # API call wrapper
â”‚   â””â”€â”€ primer.py                  # Prompt priming
â”‚
â”œâ”€â”€ micro/                          # Micro-modular architecture
â”‚   â”œâ”€â”€ conversation/              # Conversation management
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â””â”€â”€ runtime/                   # Runtime systems
â”‚       â””â”€â”€ api.py
â”‚
â”œâ”€â”€ embeddings/                     # Embedding systems
â”‚   â””â”€â”€ [embedding logic]
â”‚
â”œâ”€â”€ prompts/                        # Prompt templates
â”‚   â””â”€â”€ [prompt files]
â”‚
â”œâ”€â”€ plugins/                        # ğŸ†• Plugin system (newly added)
â”‚   â”œâ”€â”€ base.py                    # BasePlugin interface
â”‚   â”œâ”€â”€ registry.py                # Plugin registry
â”‚   â”œâ”€â”€ loader.py                  # Dynamic loader
â”‚   â”œâ”€â”€ analyzer.py                # Repo analyzer
â”‚   â”œâ”€â”€ tool_wrapper.py            # Tool wrapping
â”‚   â”œâ”€â”€ discovery.py               # Auto-discovery
â”‚   â”œâ”€â”€ runtime_integration.py     # Runtime integration
â”‚   â””â”€â”€ README.md                  # Plugin documentation
â”‚
â””â”€â”€ Service Modules:
    â”œâ”€â”€ rag_service.py             # RAG (Retrieval Augmented Generation)
    â”œâ”€â”€ parser_service.py          # Code parsing
    â”œâ”€â”€ text_service.py            # Text processing
    â””â”€â”€ spinner_service.py         # CLI spinner/progress
```

---

## ğŸš€ Key Features

### 1. **Autonomous Execution Loop**
- Safe, sandboxed code execution
- Self-healing with "pulse" mechanism
- Error tolerance with auto-decay
- Timeout-based autonomous thinking (TIMEOUT env var)

### 2. **Durable Memory System**
```
Memory Components:
- <evergreen> facts: Persistent knowledge
- Rolling context: Recent dialogue/actions
- Embeddings: Vector-based retrieval
- StateFrames: Compact state snapshots
- Brain persistence: .jinx/brain/ directory
- Memory persistence: .jinx/memory/ directory
```

### 3. **Embeddings & RAG**
```
Embedding Sources:
- dialogue: Conversation history
- project: Codebase snippets
- code: Sandbox execution outputs
- state: State frame snapshots
- verify: Verification results
```

**Key Features:**
- Real-time snippet caching (TTL + LRU + coalescing)
- File-watcher invalidation
- Semantic retrieval with boosting
- Multi-source aggregation

### 4. **Chained Reasoning System**

```
Flow: Input â†’ Planner â†’ Reflection â†’ Execution

Stages:
1. Planner Brain (JINX_CHAINED_REASONING=true)
   - Generates structured plan
   - Identifies risks and sub-queries
   - Provides guidance

2. Reflection Stage (JINX_CHAINED_REFLECT=true)
   - Reviews plan quality
   - Validates assumptions
   - Suggests improvements

3. Advisory Mode (JINX_CHAINED_ADVISORY=true)
   - Soft guidance via <plan_guidance>
   - No forced steps/code
   - Clarifications and reminders
```

### 5. **Continuity & State Management**

```
Continuity Layer (JINX_CONTINUITY_ENABLE=true):
- Short clarifications merged with past questions
- Project context caching
- Anchor extraction (questions/symbols/paths)
- Topic shift detection
- Evergreen topic guard
```

**StateFrames:**
- Compact snapshots: intent + anchors + guidance
- Stored in embeddings (source="state")
- Helps continue thoughts across turns
- Configurable boost for short queries

### 6. **Intelligent Patching System**

```
Patch Features:
- Auto-commit with change limits
- Syntax checking (Python)
- Fuzzy context matching
- Auto-indentation
- Docstring preservation
- Semantic patch for large files
```

**Semantic Patch (Large Files):**
- Embedding-guided window location
- TopK=5 retrieval
- Margin-based scoring
- Configurable tolerance

### 7. **Verification System**

```
Auto-Verification (JINX_VERIFY_AUTORUN=true):
- Embedding-based post-commit checks
- TopK=6 retrieval
- 400ms latency budget
- Pass threshold: 0.6
- Export results to prompts
```

### 8. **Prompt Macro System**

```
Macro Syntax: {{m:provider:query:N:MS}}

Built-in Providers:
- m:emb - Embedding retrieval
  Example: {{m:emb:authentication code:3:200}}
  
- m:patch - Recent patches
- m:verify - Verification results

Auto-Macros (JINX_AUTOMACROS=true):
- Auto-inject dialogue/project context
- Include patch exports
- Include verification exports
```

---

## ğŸ”§ Configuration System

### Environment Variables (.env)

#### **Required:**
```bash
OPENAI_API_KEY=<your-key>
```

#### **Core Settings:**
```bash
PULSE=120                    # Error tolerance
TIMEOUT=1000                 # Auto-thinking timeout (seconds)
OPENAI_MODEL=gpt-4.1         # Model override
PROXY=socks5://127.0.0.1:12334  # Optional proxy
```

#### **RAG & Embeddings:**
```bash
OPENAI_VECTOR_STORE_ID=vs_xxx  # Vector store IDs
OPENAI_FORCE_FILE_SEARCH=true  # Force file search

EMBED_PROJECT_ENABLE=true      # Auto-embed codebase
EMBED_PROJECT_ROOT=.           # Root directory
```

#### **Chained Reasoning:**
```bash
JINX_CHAINED_REASONING=true    # Enable planner
JINX_CHAINED_REFLECT=true      # Enable reflection
JINX_CHAINED_ADVISORY=true     # Advisory mode
JINX_CHAINED_MAX_STEPS=3       # Max plan steps
JINX_CHAINED_MAX_SUBS=2        # Max sub-queries
```

#### **Continuity:**
```bash
JINX_CONTINUITY_ENABLE=true    # Enable continuity
JINX_CONTINUITY_SHORTLEN=80    # Short clarification threshold
JINX_STATEFRAME_ENABLE=true    # Enable state frames
```

#### **Patching:**
```bash
JINX_PATCH_AUTOCOMMIT=true     # Auto-commit changes
JINX_PATCH_MAX_SPAN=80         # Max line span
JINX_PATCH_CHECK_SYNTAX=true   # Syntax validation
```

#### **Verification:**
```bash
JINX_VERIFY_AUTORUN=true       # Auto-verify commits
JINX_VERIFY_TOPK=6             # Retrieval TopK
JINX_VERIFY_PASS=0.6           # Pass threshold
```

---

## ğŸ› ï¸ Dependencies

### Runtime Dependencies (Auto-installed)
```python
# Core
- aiofiles            # Async file I/O
- prompt_toolkit      # Interactive CLI
- networkx            # Dependency graphs (new)

# OpenAI
- openai             # OpenAI SDK

# Optional
- python-dotenv      # .env file loading
- watchdog           # File watching
```

### Installation
```bash
# No requirements.txt needed!
# Runtime ensures dependencies when needed

# Just run:
python jinx.py
```

---

## ğŸ¯ Usage Patterns

### 1. **Basic Usage**
```bash
# Set up environment
cp .env.example .env
# Edit .env with your OPENAI_API_KEY

# Run agent
python jinx.py
```

### 2. **With droid2api (Z.AI Integration)**
```bash
# Terminal 1: Start droid2api
cd droid2api
npm install
npm start  # Runs on port 8765

# Terminal 2: Configure Jinx for local API
export OPENAI_API_KEY="665b963943b647dc9501dff942afb877.A47LrMc7sgGjyfBJ"
export OPENAI_BASE_URL="http://localhost:8765/v1"
export OPENAI_MODEL="glm-4.6"

python jinx.py
```

### 3. **Plugin System Usage**
```python
from jinx.plugins.runtime_integration import quick_integrate, execute_plugin_tool

# Load plugin
plugin = quick_integrate("./my_plugin.py")

# Execute tool
result = execute_plugin_tool("tool_name", arg1="value1")
```

---

## ğŸ“Š Operational Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CONTINUITY LAYER                               â”‚
â”‚  - Merge short clarifications                           â”‚
â”‚  - Check topic shift                                    â”‚
â”‚  - Load cached context                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CHAINED REASONING                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  1. Planner Brain                          â”‚         â”‚
â”‚  â”‚     - Generate plan                        â”‚         â”‚
â”‚  â”‚     - Identify risks                       â”‚         â”‚
â”‚  â”‚     - Create sub-queries                   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                  â”‚                                       â”‚
â”‚                  â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  2. Embedding Retrieval                    â”‚         â”‚
â”‚  â”‚     - Dialogue context                     â”‚         â”‚
â”‚  â”‚     - Project code                         â”‚         â”‚
â”‚  â”‚     - State frames                         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                  â”‚                                       â”‚
â”‚                  â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  3. Reflection (Optional)                  â”‚         â”‚
â”‚  â”‚     - Validate plan                        â”‚         â”‚
â”‚  â”‚     - Suggest improvements                 â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PROMPT COMPOSITION                             â”‚
â”‚  - Expand macros {{m:...}}                              â”‚
â”‚  - Include plan guidance                                â”‚
â”‚  - Add verification results                             â”‚
â”‚  - Inject auto-macros                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LLM CALL (OpenAI/droid2api)                    â”‚
â”‚  - With retry/timeout wrappers                          â”‚
â”‚  - Structured logging                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CODE EXECUTION                                 â”‚
â”‚  - Sandboxed environment                                â”‚
â”‚  - Capture stdout/stderr                                â”‚
â”‚  - Update pulse on errors                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          INTELLIGENT PATCHING                           â”‚
â”‚  - Parse code patches                                   â”‚
â”‚  - Fuzzy context matching                               â”‚
â”‚  - Syntax validation                                    â”‚
â”‚  - Auto-commit (if enabled)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          VERIFICATION                                   â”‚
â”‚  - Embedding-based checks                               â”‚
â”‚  - Generate verification report                         â”‚
â”‚  - Export to prompts                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STATE PERSISTENCE                              â”‚
â”‚  - Save StateFrame                                      â”‚
â”‚  - Update embeddings                                    â”‚
â”‚  - Persist brain/memory                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ New Plugin System (Just Added!)

### Architecture
```
jinx/plugins/
â”œâ”€â”€ base.py              - BasePlugin abstract class
â”œâ”€â”€ registry.py          - PluginRegistry singleton
â”œâ”€â”€ loader.py            - Load from paths/git
â”œâ”€â”€ analyzer.py          - Analyze repositories
â”œâ”€â”€ tool_wrapper.py      - Wrap functions as tools
â”œâ”€â”€ discovery.py         - Auto-discover plugins
â””â”€â”€ runtime_integration.py - Integrate with Jinx runtime
```

### Capabilities
1. **Dynamic Loading**: Load plugins from local paths or git repos
2. **Auto-Analysis**: Extract functions/classes from repositories
3. **Tool Wrapping**: Convert any function into a Jinx tool
4. **Hot Reload**: Reload plugins during development
5. **Auto-Discovery**: Scan standard paths for plugins

### Example Plugin
```python
from jinx.plugins.base import BasePlugin, Tool, ToolSpec

class MyPlugin(BasePlugin):
    @property
    def name(self) -> str:
        return "my_plugin"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    def initialize(self) -> None:
        def greet(name: str) -> str:
            return f"Hello, {name}!"
        
        spec = ToolSpec(
            name="greet",
            description="Greet someone",
            function=greet,
            parameters={"name": {"required": True}},
        )
        
        self._tools = [Tool(spec=spec, plugin_name=self.name)]
        self._initialized = True
    
    def get_tools(self) -> List[Tool]:
        return self._tools
```

---

## ğŸ“ Logging System

### Log Files (log/ directory)
```
log/
â”œâ”€â”€ transcript.jsonl        # Full conversation history
â”œâ”€â”€ sandbox.log             # Sandbox execution logs
â”œâ”€â”€ general.log             # General agent logs
â”œâ”€â”€ embeddings.log          # Embedding operations
â”œâ”€â”€ openai_dumps/           # Raw OpenAI API logs
â””â”€â”€ plan_trace.jsonl        # Planner tracing (if enabled)
```

---

## ğŸ¯ Use Cases

### 1. **Autonomous Coding Assistant**
- Natural language â†’ working code
- Self-healing on errors
- Context-aware suggestions

### 2. **Code Analysis & Refactoring**
- Analyze codebases
- Suggest improvements
- Apply intelligent patches

### 3. **Knowledge Management**
- Embed project documentation
- RAG-based question answering
- Persistent memory across sessions

### 4. **Testing & Verification**
- Auto-verify code changes
- Semantic correctness checks
- Export verification reports

### 5. **Plugin Extensibility**
- Load external tools dynamically
- Integrate with any Python library
- Create custom workflows

---

## ğŸš¨ Important Notes

### 1. **API Compatibility**
Jinx uses OpenAI SDK, so it's compatible with:
- OpenAI API (native)
- **droid2api** (OpenAI-compatible proxy)
- **Z.AI via droid2api** âœ… (tested and working!)
- Any OpenAI-compatible endpoint

### 2. **Model Requirements**
- Supports any OpenAI-compatible model
- Tested with: gpt-4.1, gpt-5, glm-4.6
- Requires good reasoning capabilities for planning

### 3. **Resource Requirements**
- **Memory**: Embeddings can be memory-intensive
- **Disk**: Log files and embeddings stored locally
- **Network**: API calls for LLM and embeddings

### 4. **Security Considerations**
- Sandboxed code execution
- API key in environment (not in code)
- Optional proxy support
- File watching with change tracking

---

## ğŸ”— Integration with droid2api + Z.AI

### Setup (TESTED & WORKING âœ…)

#### 1. **Start droid2api**
```bash
cd droid2api
# Edit config.json if needed (default port: 8765)
npm install
npm start
```

#### 2. **Configure Jinx**
```bash
# In .env or export:
export OPENAI_API_KEY="665b963943b647dc9501dff942afb877.A47LrMc7sgGjyfBJ"
export OPENAI_BASE_URL="http://localhost:8765/v1"
export OPENAI_MODEL="glm-4.6"
```

#### 3. **Run Jinx**
```bash
python jinx.py
```

### Verification Test
```bash
curl -X POST http://localhost:8765/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer 665b963943b647dc9501dff942afb877.A47LrMc7sgGjyfBJ" \
  -d '{
    "model": "glm-4.6",
    "messages": [{"role": "user", "content": "Test message"}],
    "max_tokens": 50
  }'

# Expected: Valid response from Z.AI via droid2api
```

---

## ğŸ“¦ Requirements Summary

### Python Requirements
```txt
# Auto-installed by Jinx runtime:
openai>=1.0.0
aiofiles
prompt_toolkit
networkx  # For plugin dependency graphs
python-dotenv  # For .env loading
watchdog  # For file watching
```

### System Requirements
```
- Python 3.9+
- Network access to API endpoint
- ~500MB disk for embeddings cache
- Optional: Node.js for droid2api
```

### droid2api Requirements (for Z.AI)
```json
{
  "dependencies": {
    "express": "^4.18.2",
    "node-fetch": "^3.3.2"
  }
}
```

---

## ğŸ¯ Next Steps for Users

### 1. **Basic Setup**
```bash
# Clone Jinx
git clone https://github.com/Zeeeepa/agent.git
cd agent

# Configure
cp .env.example .env
# Edit .env with your API key

# Run
python jinx.py
```

### 2. **Advanced Setup (with droid2api + Z.AI)**
```bash
# Terminal 1: droid2api
cd droid2api
npm install
npm start

# Terminal 2: Jinx with Z.AI
cd agent
export OPENAI_API_KEY="<your-z.ai-key>"
export OPENAI_BASE_URL="http://localhost:8765/v1"
export OPENAI_MODEL="glm-4.6"
python jinx.py
```

### 3. **Plugin Development**
```bash
# Create plugin
vi my_plugin.py

# Load in Jinx
from jinx.plugins.runtime_integration import quick_integrate
plugin = quick_integrate("my_plugin.py")
```

---

## ğŸ† Strengths & Capabilities

### âœ… **Strengths**
1. **Production-Ready**: Enterprise-grade architecture
2. **Self-Healing**: Pulse mechanism + auto-recovery
3. **Rich Memory**: Embeddings + state frames + brain persistence
4. **Intelligent Planning**: Chained reasoning with reflection
5. **Robust Patching**: Fuzzy matching + syntax validation
6. **Extensible**: Plugin system for external tools
7. **Well-Documented**: Extensive .env.example and README
8. **Model-Agnostic**: Works with any OpenAI-compatible API

### ğŸ¯ **Key Differentiators**
- **Continuity Layer**: Smart context merging across turns
- **StateFrames**: Compact state snapshots for long-term memory
- **Semantic Patching**: Embedding-guided file modification
- **Auto-Verification**: Post-commit correctness checking
- **Macro System**: Dynamic prompt composition

---

## ğŸ“ˆ Performance Characteristics

### Latency Budgets (Configurable)
```
- Planner retrieval: 100-180ms
- Verification: 400ms
- Semantic patch: 400ms
- Auto-macros: 140-500ms
```

### Resource Usage
```
- Embeddings: ~5-10MB per 1000 snippets
- Logs: ~1-5MB per session
- Memory: ~200-500MB runtime
```

---

## ğŸ” Summary

**Jinx is a sophisticated, production-ready autonomous coding agent with:**
- Advanced memory and reasoning systems
- Robust error handling and self-healing
- Extensible plugin architecture
- Intelligent code patching and verification
- Full compatibility with OpenAI-compatible APIs (including Z.AI via droid2api)

**Ideal for:**
- Autonomous code generation
- Intelligent refactoring
- Knowledge-augmented development
- Production environments requiring reliability

**Successfully tested with:**
âœ… droid2api on port 8765
âœ… Z.AI credentials (glm-4.6 model)
âœ… Plugin system implementation
âœ… Complete codebase analysis

---

*Analysis completed: 2025-01-13*
*Jinx version: Latest (main branch)*
*droid2api: 1.3.4*
*Z.AI Model: glm-4.6*

